{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eede2d84",
   "metadata": {},
   "source": [
    "# POLI 179 Final Project\n",
    "## Comparing across keywords\n",
    "### By: Alyson OtaÃ±ez "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc60a03",
   "metadata": {},
   "source": [
    "The following code applies an LDA model to subsets of `ie_cities.csv` file found in the `Data` folder to determine the difference in topics based on keyword classification.\n",
    "\n",
    "\n",
    "Keywords were determined by skimming through the agenda/minutes, and noting the words commonly used to reference industrial, recreation, and transportation issues.\n",
    "\n",
    "Plot of keywords over time can be found in the folders - `Plots` -> `Keywords_Over_Time`\n",
    "\n",
    "Topic Plot can be found in the folders - `Plots` -> `LDA_Topic_Visual` -> `Keywords`\n",
    "\n",
    "Matrix for topic differences can be found in the folders - `Plots` -> `LDA_Topic_Difference` -> `Keywords`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa9c65e",
   "metadata": {},
   "source": [
    "## Exploratory Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a5709",
   "metadata": {},
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf20647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages if necessary \n",
    "# ! pip install pandas\n",
    "# ! pip install re \n",
    "# ! pip install matplotlib\n",
    "# ! pip install seaborn\n",
    "# ! pip install warnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a92b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7d2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "ie_cities = pd.read_csv('../Data/ie_cities.csv')\n",
    "\n",
    "# Drop NA values (only 1)\n",
    "ie_cities = ie_cities[ie_cities['Text'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52098d81",
   "metadata": {},
   "source": [
    "### 2. Keywords Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa39f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords \n",
    "industrial = ['warehouse', 'logistics', 'distribution', 'industrial', 'warehousing']\n",
    "recreation = ['recreation', 'park', 'green space', 'pool', 'outdoor']\n",
    "transportation = ['transportation', 'bus', 'public transport', 'transit', 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of industrial terms over time\n",
    "def count_industrial(text):\n",
    "    words = re.split(r'\\s+', text.lower())  \n",
    "    return sum(word in industrial for word in words)\n",
    "\n",
    "# Apply the function to each text entry and create a new column for sums\n",
    "ie_cities['Sum_Industrial'] = ie_cities['Text'].apply(count_industrial)\n",
    "\n",
    "# Group by Year and sum the counts\n",
    "yearly_counts_in = ie_cities.groupby('Year')['Sum_Industrial'].sum().reset_index()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.barplot(data=yearly_counts_in, x='Year', y='Sum_Industrial', color='tomato')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count of Industrial Terms')\n",
    "plt.title('Sum of Mention of Industrial Terms in Inland Empire, CA')\n",
    "plt.savefig('industrial_terms_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03267402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of recreation terms over time\n",
    "def count_recreation(text):\n",
    "    words = re.split(r'\\s+', text.lower())  \n",
    "    return sum(word in recreation for word in words)\n",
    "\n",
    "# Apply the function to each text entry and create a new column for sums\n",
    "ie_cities['Sum_Recreation'] = ie_cities['Text'].apply(count_recreation)\n",
    "\n",
    "# Group by Year and sum the counts\n",
    "yearly_counts_re = ie_cities.groupby('Year')['Sum_Recreation'].sum().reset_index()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.barplot(data=yearly_counts_re, x='Year', y='Sum_Recreation', color='seagreen')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count of Recreation Terms')\n",
    "plt.title('Sum of Mention of Recreation Terms in Inland Empire, CA')\n",
    "plt.savefig('recreation_terms_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225ab3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of transportation terms over time\n",
    "def count_trans(text):\n",
    "    words = re.split(r'\\s+', text.lower())  \n",
    "    return sum(word in transportation for word in words)\n",
    "\n",
    "# Apply the function to each text entry and create a new column for sums\n",
    "ie_cities['Sum_Transportation'] = ie_cities['Text'].apply(count_trans)\n",
    "\n",
    "# Group by Year and sum the counts\n",
    "yearly_counts_tr = ie_cities.groupby('Year')['Sum_Transportation'].sum().reset_index()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.barplot(data=yearly_counts_tr, x='Year', y='Sum_Transportation', color='steelblue')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count of Transportation Terms')\n",
    "plt.title('Sum of Mention of Transportation Terms in Inland Empire, CA')\n",
    "plt.savefig('trans_terms_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7295ce75",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation (LDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899e929",
   "metadata": {},
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages if necessary\n",
    "# ! pip install nltk\n",
    "# ! pip install spacy \n",
    "# ! pip install --user gensim\n",
    "# ! pip install --user pyLDAvis\n",
    "# ! pip install --user gutenbergpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "sys.path.append('/home/aotanez/.local/lib/python3.9/site-packages') # Comment out\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gutenbergpy import textget\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvisualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2053eb6f",
   "metadata": {},
   "source": [
    "### 2. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b38c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordNet for lemmatization \n",
    "def wordnet_pos_tags(x):\n",
    "    if x.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif x.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif x.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif x.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1733f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing \n",
    "def txt_preprocess_pipeline(text):\n",
    "    standard_txt = text.lower()\n",
    "    \n",
    "    clean_txt = re.sub(r'http\\S+|www\\S+|https\\S+', '', standard_txt, flags = re.MULTILINE)\n",
    "    clean_txt = re.sub(r'\\n', ' ', clean_txt)\n",
    "    clean_txt = re.sub(r'\\s+', ' ', clean_txt)\n",
    "    clean_txt = re.sub(r'\\S+@\\S+', '', clean_txt)\n",
    "    clean_txt = re.sub(r'\\\\r\\\\n', ' ', clean_txt)\n",
    "    clean_txt = re.sub(r'\\s+', ' ', clean_txt)\n",
    "    clean_txt = re.sub(r'<.*?>', '', clean_txt)\n",
    "    clean_txt = re.sub(r'[^\\w\\s]', '', clean_txt)    \n",
    "    clean_txt = re.sub(r'\\b\\w{1,2}\\b', '', clean_txt)\n",
    "    \n",
    "    tokens = word_tokenize(clean_txt)\n",
    "    filtered_tokens_alpha = [word for word in tokens if word.isalpha() and not re.match(r'^[ivxlcdm]+$', word)]\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['chino', 'fontana', 'march', 'joint', 'powers', 'authority', \n",
    "                       'http', 'rialto', 'ontario', 'city', 'council', 'agenda',\n",
    "                      'meeting', 'minutes', 'back', 'site', 'main', 'welcome', 'browse', 'video',\n",
    "                      'monday', 'tuesday', 'wednesday', 'thursday', 'friday', \n",
    "                      'saturday', 'sunday', 'notice', 'commission', 'archive', 'pmcity',\n",
    "                      'chamber', 'palm', 'ave', 'january', 'february', 'march', 'april', 'may',\n",
    "                      'june', 'july', 'august', 'september', 'october', 'november', 'december',\n",
    "                      'closed', 'session'])\n",
    "    filtered_tokens_final = [w for w in filtered_tokens_alpha if not w in stop_words]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    pos_tags = nltk.pos_tag(filtered_tokens_final)\n",
    "    lemma_tokens = [lemmatizer.lemmatize(token, wordnet_pos_tags(pos_tag)) for token, pos_tag in pos_tags]\n",
    "    \n",
    "    return lemma_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bce0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply functions to data\n",
    "ie_cities['Processed_Text'] = ie_cities['Text'].apply(txt_preprocess_pipeline)\n",
    "ie_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d747b24",
   "metadata": {},
   "source": [
    "### 3. Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd9a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column to classify text based on max keywords mentioned \n",
    "ie_cities['Type'] = ie_cities[['Sum_Industrial', 'Sum_Recreation', 'Sum_Transportation']].idxmax(axis=1)\n",
    "\n",
    "rename = {'Sum_Industrial': 'Industrial', \n",
    "          'Sum_Recreation': 'Recreation', \n",
    "          'Sum_Transportation': 'Transportation'}\n",
    "\n",
    "ie_cities['Type'] = ie_cities['Type'].map(rename)\n",
    "\n",
    "ie_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de85fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Industrial \n",
    "industrial = ie_cities[ie_cities['Type'] == 'Industrial']\n",
    "industrial\n",
    "\n",
    "# N = 3,157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreation \n",
    "recreation = ie_cities[ie_cities['Type'] == 'Recreation']\n",
    "recreation\n",
    "\n",
    "# N = 1,795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fd69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transportation\n",
    "transportation = ie_cities[ie_cities['Type'] == 'Transportation']\n",
    "transportation\n",
    "\n",
    "# N = 573"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea6ff8b",
   "metadata": {},
   "source": [
    "### 4. Train LDA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b8bd8",
   "metadata": {},
   "source": [
    "### 4.1 Industrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a13f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary\n",
    "dictionary_in = corpora.Dictionary(industrial['Processed_Text'])\n",
    "dictionary_in.filter_extremes(no_below = 2)\n",
    "\n",
    "# Generate corpus as BoW\n",
    "corpus_in = [dictionary_in.doc2bow(i) for i in  industrial['Processed_Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a47d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "lda_model_in = LdaModel(corpus = corpus_in, id2word = dictionary_in, random_state = 4583, \n",
    "                     chunksize = 20, num_topics = 5, passes = 200, iterations= 400)\n",
    "\n",
    "# Print LDA topics\n",
    "for idx, topic in lda_model_in.print_topics(num_topics = 5, num_words =10):\n",
    "    print(f\"Topic {idx+1}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cacd5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "dickens_visual_in = gensimvisualize.prepare(lda_model_in, corpus_in, dictionary_in, mds='mmds')\n",
    "pyLDAvis.save_html(dickens_visual_in, 'lda_industrial_visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b448dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "pyLDAvis.display(dickens_visual_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03553f94",
   "metadata": {},
   "source": [
    "### 4.2 Recreation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eca720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary\n",
    "dictionary_re = corpora.Dictionary(recreation['Processed_Text'])\n",
    "dictionary_re.filter_extremes(no_below = 2)\n",
    "\n",
    "# Generate corpus as BoW\n",
    "corpus_re = [dictionary_re.doc2bow(i) for i in recreation['Processed_Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e46e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "lda_model_re = LdaModel(corpus = corpus_re, id2word = dictionary_re, random_state = 4583, \n",
    "                     chunksize = 20, num_topics = 5, passes = 200, iterations= 400)\n",
    "\n",
    "# Print LDA topics\n",
    "for idx, topic in lda_model_re.print_topics(num_topics = 5, num_words =10):\n",
    "    print(f\"Topic {idx+1}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e24fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "dickens_visual_re = gensimvisualize.prepare(lda_model_re, corpus_re, dictionary_re, mds='mmds')\n",
    "pyLDAvis.save_html(dickens_visual_re, 'lda_recreation_visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793f0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "pyLDAvis.display(dickens_visual_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d5409d",
   "metadata": {},
   "source": [
    "### 4.3 Transportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5638d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary\n",
    "dictionary_tr = corpora.Dictionary(transportation['Processed_Text'])\n",
    "dictionary_tr.filter_extremes(no_below = 2)\n",
    "\n",
    "# Generate corpus as BoW\n",
    "corpus_tr = [dictionary_tr.doc2bow(i) for i in transportation['Processed_Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae448d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "lda_model_tr = LdaModel(corpus = corpus_tr, id2word = dictionary_tr, random_state = 4583, \n",
    "                     chunksize = 20, num_topics = 5, passes = 200, iterations= 400)\n",
    "\n",
    "# Print LDA topics\n",
    "for idx, topic in lda_model_tr.print_topics(num_topics = 5, num_words =10):\n",
    "    print(f\"Topic {idx+1}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb627388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "dickens_visual_tr = gensimvisualize.prepare(lda_model_tr, corpus_tr, dictionary_tr, mds='mmds')\n",
    "pyLDAvis.save_html(dickens_visual_tr, 'lda_transportation_visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ad633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "pyLDAvis.display(dickens_visual_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7d910b",
   "metadata": {},
   "source": [
    "### 5. Topic Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a086d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot difference function\n",
    "## Source: https://radimrehurek.com/gensim/auto_examples/howtos/run_compare_lda.html#:~:text=You%20can%20do%20this%20by%20constructing%20a%20matrix%20with%20the%20difference.&text=Looking%20at%20this%20matrix%2C%20you,the%20topics'%20intersection%20and%20difference.\n",
    "\n",
    "def plot_difference_plotly(mdiff, title=\"\", annotation=None):\n",
    "    annotation_html = None\n",
    "    if annotation is not None:\n",
    "        annotation_html = [\n",
    "            [\n",
    "                \"+++ {}<br>--- {}\".format(\", \".join(int_tokens), \", \".join(diff_tokens))\n",
    "                for (int_tokens, diff_tokens) in row\n",
    "            ]\n",
    "            for row in annotation\n",
    "        ]\n",
    "\n",
    "    data = go.Heatmap(z=mdiff, colorscale='RdBu', text=annotation_html)\n",
    "    layout = go.Layout(width=950, height=950, title=title, xaxis=dict(title=\"topic\"), yaxis=dict(title=\"topic\"))\n",
    "    fig = go.Figure(data=[data], layout=layout)\n",
    "    return fig\n",
    "\n",
    "def plot_difference_matplotlib(mdiff, title=\"\", annotation=None):\n",
    "    fig, ax = plt.subplots(figsize=(18, 14))\n",
    "    data = ax.imshow(mdiff, cmap='RdBu_r', origin='lower')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(data)\n",
    "    plt.show()\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "    import plotly.offline as py\n",
    "except Exception:\n",
    "    plot_difference = plot_difference_matplotlib\n",
    "else:\n",
    "    py.init_notebook_mode()\n",
    "    plot_difference = plot_difference_plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed9faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference matrix\n",
    "# Industrial vs. Recreation\n",
    "mdiff, annotation = lda_model_in.diff(lda_model_re, distance = 'jaccard', num_words = 50)\n",
    "diff1 = plot_difference(mdiff, title= \"Topic difference Industrial vs. Recreation\", annotation=annotation)\n",
    "py.plot(diff1, filename='indrec_topic_diff.html')\n",
    "diff1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2929ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference matrix\n",
    "# Industrial vs. Transportation\n",
    "mdiff, annotation = lda_model_in.diff(lda_model_tr, distance = 'jaccard', num_words = 50)\n",
    "diff2 = plot_difference(mdiff, title= \"Topic difference Industrial vs. Transportation\", annotation=annotation)\n",
    "py.plot(diff2, filename='indtra_topic_diff.html')\n",
    "diff2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
