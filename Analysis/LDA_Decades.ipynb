{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eede2d84",
   "metadata": {},
   "source": [
    "# POLI 179 Final Project\n",
    "## 2 Decades\n",
    "### By: Alyson OtaÃ±ez "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31889398",
   "metadata": {},
   "source": [
    "The following code applies an LDA model to subsets of `ie_cities.csv` file found in the `Data` folder to determine the difference in topics between 2 decades of data.\n",
    "\n",
    "Given lack of older data, I analyze 2 decades: 2003 - 2013 & 2014 - 2024\n",
    "\n",
    "Topic Plot can be found in the folders - `Plots` -> `LDA_Topic_Visual` -> `Decades`\n",
    "\n",
    "Matrix for topic differences can be found in the folders - `Plots` -> `LDA_Topic_Difference` -> `Decades`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c669180",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis (LDA) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7cdbb",
   "metadata": {},
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab19822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages if necessary\n",
    "# ! pip install nltk\n",
    "# ! pip install spacy \n",
    "# ! pip install --user gensim\n",
    "# ! pip install --user pyLDAvis\n",
    "# ! pip install --user gutenbergpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb1db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import sys\n",
    "sys.path.append('/home/aotanez/.local/lib/python3.9/site-packages')\n",
    "import gensim\n",
    "import numpy as np\n",
    "from gutenbergpy import textget\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvisualize\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "ie_cities = pd.read_csv('../Data/ie_cities.csv')\n",
    "\n",
    "# Drop NA values (only 1)\n",
    "ie_cities = ie_cities[ie_cities['Text'].notna()]\n",
    "\n",
    "ie_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f930e71",
   "metadata": {},
   "source": [
    "### 2. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordNet for lemmatization \n",
    "def wordnet_pos_tags(x):\n",
    "    if x.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif x.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif x.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif x.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for preprocessing \n",
    "def txt_preprocess_pipeline(text):\n",
    "    standard_txt = text.lower()\n",
    "    \n",
    "    clean_txt = re.sub(r'http\\S+|www\\S+|https\\S+', '', standard_txt, flags = re.MULTILINE)\n",
    "    clean_txt = re.sub(r'\\n', ' ', clean_txt)\n",
    "    clean_txt = re.sub(r'\\s+', ' ', clean_txt)\n",
    "    clean_txt = re.sub(r'\\S+@\\S+', '', clean_txt)\n",
    "    clean_txt = re.sub(r'\\\\r\\\\n', ' ', clean_txt)\n",
    "    clean_txt = re.sub(r'\\s+', ' ', clean_txt)\n",
    "    clean_txt = re.sub(r'<.*?>', '', clean_txt)\n",
    "    clean_txt = re.sub(r'[^\\w\\s]', '', clean_txt)    \n",
    "    clean_txt = re.sub(r'\\b\\w{1,2}\\b', '', clean_txt)\n",
    "    \n",
    "    tokens = word_tokenize(clean_txt)\n",
    "    filtered_tokens_alpha = [word for word in tokens if word.isalpha() and not re.match(r'^[ivxlcdm]+$', word)]\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['chino', 'fontana', 'march', 'joint', 'powers', 'authority', \n",
    "                       'http', 'rialto', 'ontario', 'city', 'council', 'agenda',\n",
    "                      'meeting', 'minutes'])\n",
    "    filtered_tokens_final = [w for w in filtered_tokens_alpha if not w in stop_words]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    pos_tags = nltk.pos_tag(filtered_tokens_final)\n",
    "    lemma_tokens = [lemmatizer.lemmatize(token, wordnet_pos_tags(pos_tag)) for token, pos_tag in pos_tags]\n",
    "    \n",
    "    return lemma_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c704cbc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply functions to data\n",
    "ie_cities['Processed_Text'] = ie_cities['Text'].apply(txt_preprocess_pipeline)\n",
    "ie_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd85ddf",
   "metadata": {},
   "source": [
    "### 3. Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fae9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decade 1 2003 - 2013\n",
    "dec_1 = ie_cities[(ie_cities['Year'] >= 2003) & (ie_cities['Year'] <= 2013)]\n",
    "dec_1\n",
    "\n",
    "# N = 1,122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4598beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decade 2 2014 - 2024\n",
    "dec_2 = ie_cities[(ie_cities['Year'] >= 2014) & (ie_cities['Year'] <= 2024)]\n",
    "dec_2\n",
    "\n",
    "# N = 4,150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf81675",
   "metadata": {},
   "source": [
    "### 4. Train LDA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f99a11",
   "metadata": {},
   "source": [
    "### 4.1 2003 - 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac0e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary\n",
    "dictionary_dec1 = corpora.Dictionary(dec_1['Processed_Text'])\n",
    "dictionary_dec1.filter_extremes(no_below = 2)\n",
    "\n",
    "# Generate corpus as BoW\n",
    "corpus_dec1 = [dictionary_dec1.doc2bow(i) for i in dec_1['Processed_Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "lda_model_dec1 = LdaModel(corpus = corpus_dec1, id2word = dictionary_dec1, random_state = 4583, \n",
    "                     chunksize = 20, num_topics = 5, passes = 200, iterations= 400)\n",
    "\n",
    "# Print LDA topics\n",
    "for idx, topic in lda_model_dec1.print_topics(num_topics = 5, num_words =10):\n",
    "    print(f\"Topic {idx+1}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be3ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "dickens_visual_dec1 = gensimvisualize.prepare(lda_model_dec1, corpus_dec1, dictionary_dec1, mds='mmds')\n",
    "pyLDAvis.save_html(dickens_visual_dec1, 'lda_decade1_visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "pyLDAvis.display(dickens_visual_dec1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8051ee4e",
   "metadata": {},
   "source": [
    "### 4.2 2014 - 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0dc50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionary\n",
    "dictionary_dec2 = corpora.Dictionary(dec_2['Processed_Text'])\n",
    "dictionary_dec2.filter_extremes(no_below = 2)\n",
    "\n",
    "# Generate corpus as BoW\n",
    "corpus_dec2 = [dictionary_dec2.doc2bow(i) for i in dec_2['Processed_Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af432c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "lda_model_dec2 = LdaModel(corpus = corpus_dec2, id2word = dictionary_dec2, random_state = 4583, \n",
    "                     chunksize = 20, num_topics = 5, passes = 200, iterations= 400)\n",
    "\n",
    "# Print LDA topics\n",
    "for idx, topic in lda_model_dec2.print_topics(num_topics = 5, num_words =10):\n",
    "    print(f\"Topic {idx+1}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d93a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "dickens_visual_dec2 = gensimvisualize.prepare(lda_model_dec2, corpus_dec2, dictionary_dec2, mds='mmds')\n",
    "pyLDAvis.save_html(dickens_visual_dec2, 'lda_decade2_visualization.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb23b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "pyLDAvis.display(dickens_visual_dec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3108cf1",
   "metadata": {},
   "source": [
    "### 5. Topic Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0065ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot difference function\n",
    "## Source: https://radimrehurek.com/gensim/auto_examples/howtos/run_compare_lda.html#:~:text=You%20can%20do%20this%20by%20constructing%20a%20matrix%20with%20the%20difference.&text=Looking%20at%20this%20matrix%2C%20you,the%20topics'%20intersection%20and%20difference.\n",
    "\n",
    "def plot_difference_plotly(mdiff, title=\"\", annotation=None):\n",
    "    annotation_html = None\n",
    "    if annotation is not None:\n",
    "        annotation_html = [\n",
    "            [\n",
    "                \"+++ {}<br>--- {}\".format(\", \".join(int_tokens), \", \".join(diff_tokens))\n",
    "                for (int_tokens, diff_tokens) in row\n",
    "            ]\n",
    "            for row in annotation\n",
    "        ]\n",
    "\n",
    "    data = go.Heatmap(z=mdiff, colorscale='RdBu', text=annotation_html)\n",
    "    layout = go.Layout(width=950, height=950, title=title, xaxis=dict(title=\"topic\"), yaxis=dict(title=\"topic\"))\n",
    "    fig = go.Figure(data=[data], layout=layout)\n",
    "    return fig\n",
    "\n",
    "def plot_difference_matplotlib(mdiff, title=\"\", annotation=None):\n",
    "    fig, ax = plt.subplots(figsize=(18, 14))\n",
    "    data = ax.imshow(mdiff, cmap='RdBu_r', origin='lower')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(data)\n",
    "    plt.show()\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "    import plotly.offline as py\n",
    "except Exception:\n",
    "    plot_difference = plot_difference_matplotlib\n",
    "else:\n",
    "    py.init_notebook_mode()\n",
    "    plot_difference = plot_difference_plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference matrix\n",
    "mdiff, annotation = lda_model_dec1.diff(lda_model_dec2, distance = 'jaccard', num_words = 50)\n",
    "diff = plot_difference(mdiff, title= \"Topic difference 2003-2013 vs. 2014-2024\", annotation=annotation)\n",
    "py.plot(diff, filename='decade_topic_diff.html')\n",
    "diff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
