---
title: "Poli 179 Final Project"
author: "By: Alyson Ota√±ez"
output: html_document
---
###### Web scraping city council website agendas for the city of Chino, CA
####### Website Link:
- Website link - http://chinocityca.iqm2.com/Citizens/Calendar.aspx 

#### Setup
```{r eval=FALSE, include=TRUE}

# Clean environment
rm(list=ls(all=TRUE))

# Install Packages if necessary 
#install.packages('rvest')
#install.packages('xml2')
#install.packages('dplyr)
#install.packages('gsubfn')
#install.packages('purrr')

# Load packages 
require(rvest)
require(xml2) 
require(dplyr)
require(gsubfn)
require(purrr)
```

#### Load website 
```{r eval=FALSE, include=TRUE}
# Setwd
setwd('')

# Load website 
url_chino <- 'http://chinocityca.iqm2.com/Citizens/Calendar.aspx?From=1/1/1900&To=12/31/9999'
chino <- read_html(url_chino)
chino
```

#### Setup for scraping 
```{r eval=FALSE, include=TRUE}
# Gather links within site 
chino.list <- chino %>% 
  html_nodes('a') %>%
  html_attr('href')
print(chino.list)

# Filter links that correspond to a meeting agenda and add the missing part of the link
chino.list <- chino.list[grep('/Citizens/Detail_Meeting', chino.list)]
chino.list <- paste('http://chinocityca.iqm2.com', chino.list, sep = "") 
chino.list

# Empty data frame to store results 
df <- data.frame(text = character(), stringsAsFactors = FALSE)
```

#### Loop to save text to data frame
```{r eval=FALSE, include=TRUE}
# For loop to iterate over each meeting agenda and gather the text, saving to empty df 
for (url in chino.list) {
  Sys.sleep(runif(1,1,5))
  page <- read_html(url)
  text_p <- page %>%
    html_nodes('body') %>%
    html_text() %>%
    trimws()
  date <- strapplyc(text_p, "\\d+/\\d+/\\d+", simplify = TRUE) 
  df <- rbind(df, data.frame(text = text_p, date = date), stringsAsFactors = FALSE)
}
df

# Save as csv
write.csv(df, 'chino_meetings.csv')

write.csv(chino, 'chino.csv')
```